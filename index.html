<script src="http://www.google.com/jsapi" type="text/javascript"></script> 
<script type="text/javascript">google.load("jquery", "1.3.2");</script>

<style type="text/css">
	body {
		font-family: "HelveticaNeue-Light", "Helvetica Neue Light", "Helvetica Neue", Helvetica, Arial, "Lucida Grande", sans-serif; 
		font-weight:300;
		font-size:16px;
		margin-left: auto;
		margin-right: auto;
		width: 800px;
	}
	
	h1 {
		font-weight:300;
	}
		
	h2 {
		font-weight:300;
		font-size: 22px;
		text-align: left;
	}

	.disclaimerbox {
		background-color: #eee;		
		border: 1px solid #eeeeee;
		border-radius: 10px ;
		-moz-border-radius: 10px ;
		-webkit-border-radius: 10px ;
		padding: 20px;
	}

	video.header-vid {
		height: 140px;
		border: 1px solid black;
		border-radius: 10px ;
		-moz-border-radius: 10px ;
		-webkit-border-radius: 10px ;
	}
	
	img.header-img {
		height: 140px;
		border: 1px solid black;
		border-radius: 10px ;
		-moz-border-radius: 10px ;
		-webkit-border-radius: 10px ;
	}
	
	img.rounded {
		border: 1px solid #eeeeee;
		border-radius: 10px ;
		-moz-border-radius: 10px ;
		-webkit-border-radius: 10px ;
	}
	
	a:link,a:visited
	{
		color: #1367a7;
		text-decoration: none;
	}
	a:hover {
		color: #208799;
	}
	
	td.dl-link {
		height: 160px;
		text-align: center;
		font-size: 22px;
	}
	
	.layered-paper-big { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
		box-shadow:
		        0px 0px 1px 1px rgba(0,0,0,0.35), /* The top layer shadow */
		        5px 5px 0 0px #fff, /* The second layer */
		        5px 5px 1px 1px rgba(0,0,0,0.35), /* The second layer shadow */
		        10px 10px 0 0px #fff, /* The third layer */
		        10px 10px 1px 1px rgba(0,0,0,0.35), /* The third layer shadow */
		        15px 15px 0 0px #fff, /* The fourth layer */
		        15px 15px 1px 1px rgba(0,0,0,0.35), /* The fourth layer shadow */
		        20px 20px 0 0px #fff, /* The fifth layer */
		        20px 20px 1px 1px rgba(0,0,0,0.35), /* The fifth layer shadow */
		        25px 25px 0 0px #fff, /* The fifth layer */
		        25px 25px 1px 1px rgba(0,0,0,0.35); /* The fifth layer shadow */
		margin-left: 10px;
		margin-right: 45px;
	}

	.paper-big { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
		box-shadow:
		        0px 0px 1px 1px rgba(0,0,0,0.35); /* The top layer shadow */

		margin-left: 10px;
		margin-right: 45px;
	}


	.layered-paper { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
		box-shadow:
		        0px 0px 1px 1px rgba(0,0,0,0.35), /* The top layer shadow */
		        5px 5px 0 0px #fff, /* The second layer */
		        5px 5px 1px 1px rgba(0,0,0,0.35), /* The second layer shadow */
		        10px 10px 0 0px #fff, /* The third layer */
		        10px 10px 1px 1px rgba(0,0,0,0.35); /* The third layer shadow */
		margin-top: 5px;
		margin-left: 10px;
		margin-right: 30px;
		margin-bottom: 5px;
	}
	
	.vert-cent {
		position: relative;
	    top: 50%;
	    transform: translateY(-50%);
	}
	
	hr
	{
		border: 0;
		height: 1px;
		background-image: linear-gradient(to right, rgba(0, 0, 0, 0), rgba(0, 0, 0, 0.75), rgba(0, 0, 0, 0));
	}

	pre {
    text-align: left;
    white-space: pre;
	background-color: ghostwhite;
	border: 1px solid #CCCCCC;
	padding: 10px 20px;
	margin: 10px;
    tab-size:         4; /* Chrome 21+, Safari 6.1+, Opera 15+ */
    -moz-tab-size:    4; /* Firefox 4+ */
    -o-tab-size:      4; /* Opera 11.5 & 12.1 only */
  	}

</style>

<html>
  <head>
		<title>iMiGUE: An Identity-free Video Dataset for Micro-Gesture Understanding and Emotion Analysis</title>
		<meta property="og:image" content=""/>
		<meta property="og:title" content="An Identity-free Video Dataset for Micro-Gesture Understanding and Emotion Analysis" />
  </head>

  <body>
    <br>
          <center>
          	<span style="font-size:36px">iMiGUE: An Identity-free Video Dataset for Micro-Gesture Understanding and Emotion Analysis</span>
	  		  <table align=center width=600px>
	  			  <tr>
	  	              <td align=center width=100px>
	  					<center>
	  						<span style="font-size:18px"><a href="https://sdolivia.github.io/">Xin Liu</a></span>
		  		  		</center>
		  		  	  </td>
	  	              <td align=center width=150px>
	  					<center>
	  						<span style="font-size:18px"><a href="http://zhaoyue-zephyrus.github.io/">Henglin Shi</a></span>
		  		  		</center>
		  		  	  </td>
	  	              <td align=center width=150px>
	  					<center>
	  						<span style="font-size:18px"><a href="http://daibo.info/">Haoyu Chen</a></span>
		  		  		</center>
		  		  	  </td>
	  	              <td align=center width=100px>
	  					<center>
	  						<span style="font-size:18px"><a href="http://daibo.info/">Zitong Yu</a></span>
		  		  		</center>
		  		  	  </td>
	  	              <td align=center width=100px>
	  					<center>
	  						<span style="font-size:18px"><a href="http://daibo.info/">Xiaobai Li</a></span>
		  		  		</center>
		  		  	  </td>
					<td align=center width=150px>
						<center>
							<span style="font-size:18px"><a href="http://dahua.me/">Guoying Zhao</a></span>
						</center>
					</td>
				</table>


			  <table align=center width=600px>
				  <tr>
					  <td align=center width=100px>
						<center>
							<span style="font-size:18px"><a href="http://www.cuhk.edu.hk/english/index.html">Center for Machine Vision and Signal Analysis, University of Oulu, Finland</a></span>
						</center>
						<center>
							<span style="font-size:18px"><a href="http://www.cuhk.edu.hk/english/index.html">School of Electrical and Information Engineering, Tianjin University, China</a></span>
						</center>
					  </td>
			  </table>
			IEEE Conference on Computer Vision and Pattern Recognition (<a href="http://cvpr2020.thecvf.com/" target="_blank">CVPR</a>) 2021, <font color="#e86e14">Oral Presentation</font>
          </center>

   		  <br><br>
		  <hr>

  		  <br>
  		  <table align=center width=720px>
  			  <tr>
  	              <td width=400px>
  					<center>
  	                	<a href="./images/Fig2.png"><img class="rounded" src = "./images/Fig2.png" width="800px"></img></href></a><br>
					</center>
  	              </td>
                </tr>
  	              <td width=400px>
  					<center>
						<style>
							

							div {
							
							text-align-last:justify;					
							text-align:justify;					
							text-justify:distribute-all-lines; 					
							width: 800px;
							
							}					
							</style>
							<div><i>此处可以添加一些对图片的.
								描述性语句.
								There are three levels of categorical labels.
								The temporal dimension (represented by the two bars) is also divided into two levels, i.e., actions and sub-actions.
								Sub-actions could be described generally using set categories or precisely using element categories.
								Ground-truth element categories </i></div>
							<i>of sub-action instances are obtained via manually constructed decision-trees.</i>
					</center>
  	              </td>

  		  </table>
      	  <br><br>

		  <table align=center width=720px>
			<!-- <center><h1>Download</h1></center> -->
			<tr>
				<td width=300px>
					<center>
						<a href="#download"><img class="rounded" onmouseover="this.src='./images/download.png';" onmouseout="this.src='./images/download.png';" src = "./images/download.png" height = "120px"></a><br>
						<span style="font-size:16px">Download</span><br>
					</center>
				</td>
				<td width=300px>
					<center>
						<a href="#video"><img class="rounded" onmouseover="this.src='./images/video.png';" onmouseout="this.src='./images/video.png';" src = "./images/video.png" height = "120px"></a><br>
						<span style="font-size:16px">Videos at CVPR'2021</span><br>
					</center>
				</td>
				<td width=300px>
					<center>
						<a href="#analysis"><img class="rounded" onmouseover="this.src='./images/analysis.png';" onmouseout="this.src='./images/analysis.png';" src = "./images/analysis.png" height = "120px"></a><br>
						<span style="font-size:16px">Analysis</span><br>
					</center>
				</td>
				<td width=300px>
					<center>
					  <a href="https://github.com/linuxsino/iMiGUE"><img class="rounded" onmouseover="this.src='./images/github.png';" onmouseout="this.src='./images/github.png';" src = "./images/github.png" height = "120px"></a><br>
					  <span style="font-size:16px">GitHub Repo</span><br>						
					</center>
				</td>
			</tr>
		  </table>

		  <br><br>

		  <hr>

  		  <table align=center width=720px>
				<center><h1>Abstract</h1></center>
		  </table>

			<span>
				<style>

					div {
					
					text-align-last:justify;					
					text-align:justify;					
					text-justify:distribute-all-lines; 					
					width: 800px;
					
					}					
					</style>
					<div>We introduce a new dataset for the emotional artificial intelligence research: 
						<i>i</i>dentity-free video dataset for <i>Mi</i>cro<i>G</i>esture <i>U</i>nderstanding and <i>E</i>motion analysis (iMiGUE). 
						Different from existing public datasets, iMiGUE focuses on nonverbal body gestures without using any identity information, 
						while the predominant researches of emotion analysis concern sensitive biometric data, like face and speech. Most importantly, 
						iMiGUE focuses on micro-gestures, i.e., unintentional behaviors driven by inner feelings, 
						which are different from ordinary scope of gestures from other gesture datasets 
						which are mostly intentionally performed for illustrative purposes. Furthermore, 
						iMiGUE is designed to evaluate the ability of models to analyze the emotional states by integrating information of recognized micro-gesture, 
						rather than just recognizing prototypes in the sequences separately (or isolatedly). 
						This is because the real need for emotion AI is to understand the emotional states behind gestures in a holistic way. 
						Moreover , to counter for the challenge of imbalanced samples distribution of this dataset, 
						an unsupervised learning method is proposed to capture latent representations from the micro-gesture sequences themselves. 
						We systematically investigate representative methods on this dataset, 
						and comprehensive experimental results reveal several interesting insights from the iMiGUE, 
						e.g., micro-gesture-based analysis can promote emotion understanding. 
						We confirm that the new iMiGUE dataset could advance studies of micro-</div>
			gesture and emotion AI.
		  	</span>

  		  <br><br>
		  <hr>

		  <table align=center width=720px>
			<center><h1>Demo video</h1></center>

			<tr>
				<table align=center width=720px>
					<tr>
						<td align=center width=720px>
							<video width="600" height="320" controls autoplay>
								<source src="images/demo.mp4" type="video/mp4">
							</video>
						</td>
					  </tr>
					<tr>
						<td align=center width=720px>
						  <span style="font-size:14px"><i>
							此处添加对视频的描述性语句.</i>
						</span>
						   </td>
					  </tr>
					 </table>
			  </tr>
		  </table>
		   <br><br>
		  <hr>

		  <table id="video" align=center width=720px>
			<center><h1>5-Minute Oral presentation video</h1></center>
			<tr>
				<table align=center width=720px>
					<tr>
						<td align=center width=720px>
							<video width="600" height="320" controls autoplay>
								<source src="images/imigue.mp4" type="video/mp4">
							</video>

						</td>
					  </tr>
					<tr>
					 </table>
			  </tr>
		  </table>
		   <br><br>
		  <hr>

		  <table align=center width=720px>
			<center><h1>1-Minute presentation video</h1></center>
			<tr>
				<table align=center width=720px>
					<tr>
						<td align=center width=720px>
							<iframe width="600" height="320" src="https://www.youtube.com/embed/b1Sm1WDcypw" frameborder="0" allowfullscreen></iframe>
						</td>
					  </tr>
					<tr>
					 </table>
			  </tr>
		  </table>
		   <br><br>
		  <hr>


		  <table align=center width=720px>
			<center><h1>Dataset Statistics and Properties</h1></center>
			<tr>
				<td width=400px>
				  <center>
					  <a><img class="rounded" src = "./images/dataset.png" width="800px"></img></a><br>
				</center>
				</td>
			</tr>
				<td width=400px>
				  <center>
					  <span style="font-size:14px"><i>
						We collected 359 videos of post match press conferences of Grand Slam tournaments. Here is the information of the iMiGUE. 
						This dataset contains 72 players from 28 countries and regions covering very continent which enables MGs analysis from diverse cultures. 
						iMiGUE comprises 36 female and 36 male players whose ages are between 17 and 38.
						</i>
				</center>
				</td>

		  </table>
	      <br><br>
		  <hr>

		  <table align=center width=720px>
			<center><h1>Micro-Gestures examples</h1></center>
			<tr>
				<center>
				<span>
					此处可添加描述性语句</span>
				<br>
				</center>
				<td width=360px>
					<center>
						<span style="font-size:22px"><a>Folding arms</a></span><br>
						<a><img onmouseover="this.src='./images/folding-arms.gif';" onmouseout="this.src='./images/folding-arms.gif';" src = "./images/folding-arms.gif" width = "400px"></img></a>
					</center>
				</td>
				<td width=360px>
					<center>
						<span style="font-size:22px"><a>Covering Face</a></span><br>
						<a><img onmouseover="this.src='./images/covering-face.gif';" onmouseout="this.src='./images/covering-face.gif';" src = "./images/covering-face.gif" width = "400px"></img></a>
					</center>
				</td>
			</tr>
			<tr>
				<td width=360px>
					<center>
						<span style="font-size:22px"><a>Scratching neck</a></span><br>
						<a><img onmouseover="this.src='./images/scratching-neck.gif';" onmouseout="this.src='./images/scratching-neck.gif';" src = "./images/scratching-neck.gif" width = "400px"></img></a>
					</center>
				</td>
				<td width=360px>
					<center>
						<span style="font-size:22px"><a>Rubbing eyes</a></span><br>
						<a><img onmouseover="this.src='./images/rubbing-eyes.gif';" onmouseout="this.src='./images/rubbing-eyes.gif';" src = "./images/rubbing-eyes.gif" width = "400px"></img></a>
					</center>
				</td>
			</tr>
		  </table>

		  <br><br>
		  <hr>

		  <table id='analysis' align=center width=720px>
			<center><h1>Empirical Studies and Analysis</h1></center>
			<table>
			<center><h2> (1) Comparison with other datasets. </h2></center>
			<tr>
				  <td width=400px>
				  <center>
					  <a><img class="rounded" src = "./images/dataset.JPG" width="800px"></img></a><br>
				</center>
				</td>
			</tr>
			<tr>
				<td align=center width=720px>
				  <span style="font-size:14px"><i>
					The attributes comparison of iMiGUE with other widely used datasets for recognizing gesture-based expression of emotion. F/M: Female/Male, 
					C: Controlled (in-the-lab), U: Uncontrolled (in-the-wild), SP: Spontaneous, F: Face, G: Gesture, V: V oice, IMG: Identity-free Micro-Gesture.</i>
				</span>
				</td>
			</tr>
			</table>

			<br>

			<table>
			<center><h2> (2) Comparison of MG recognition accuracy with SOTA algorithms on iMiGUE. </h2></center>
			<tr>
				  <td width=400px>
				  <center>
					  <a><img class="rounded" src = "./images/accuracy.JPG" width="500px"></img></a><br>
				</center>
				</td>
			</tr>
			<tr>
				<td align=center width=720px>
				  <span style="font-size:14px"><i>
					Comparison of MG recognition accuracy (%) with stateof-the-art algorithms on the iMiGUE dataset (best: bold, second best: underlined).</i>
				</span>
				</td>
			</tr>
			</table>

			<br>

			<table>
				<center><h2> (3) Comparison of emotion understanding accuracy with methods on iMiGUE </h2></center>
				<tr>
					  <td width=400px>
					  <center>
						  <a><img class="rounded" src = "./images/emotion.JPG" width="600px"></img></a><br>
					</center>
					</td>
				</tr>
				<tr>
					<td align=center width=720px>
					  <span style="font-size:14px"><i>
						Comparison of emotion understanding accuracy (%) with methods on iMiGUE dataset (best: bold, second best: underlined).</i>
					</span>
					</td>
				</tr>
				</table>

			<br>

			<table>
				<center><h2> (4) Ablation study of U-S-V AE with different datasets </h2></center>
				<tr>
					<td width=400px>
					<center>
						<a><img class="rounded" src = "./images/ablation.JPG" width="600px"></img></a>
					</center>
					</td>
				</tr>
				<tr>
					<td align=center width=720px>
					<span style="font-size:14px"><i>
					Ablation study of U-S-V AE with different datasets (best: bold, second best: underlined).</i>
					</span>
					</td>
				</tr>
				</table>

			<br>
			

					
		</table>
	      <br><br>
		  <hr>


		  <table id="download" align=center width=720px>
			<center><h1>Download</h1></center>
			<tr>
				<td width=300px>
					<center>
						<span style="font-size:24px">Label</span><br>
						<br>
						<span style="font-size:18px"><a href="https://drive.google.com/drive/folders/1DAvao-AfHXPn_0IxMvbWeQS6bPfM-oDu">Excel</a></span><br>
						<span style="font-size:16px"><a href='https://drive.google.com/drive/folders/1Opu2VGh4LTfL1Ua-jN0UTwO-Joairguw'>Raw</a></span><br>
					<span style="font-size:16px"></span>
					</center>
				</td>
				<td width=300px>
					<center>
						<span style="font-size:24px">Data</span><br>
						<br>
						<span style="font-size:16px"><a href='https://drive.google.com/drive/folders/1zNtMoWpG5mAVxZsQWz3X5NoxTCf8qgmw'>Excel</a></span><br>
						<span style="font-size:16px"><a href='https://drive.google.com/file/d/1W5rmjUm3TXnq0L_NeI56YMd1ZZ-wUxYY/view'>Raw</a></span><br>
					<span style="font-size:16px"></span>
					</center>
				</td>
			</tr>
		</table>
			
		
		 <table id = "News!" align=center width=720px>
			<hr>
				<center><h1> News! </h1></center>
				[10/06/2021] We have made iMiGUE dataset available at Google Drive. Check out <a href="#download">here</a>.<br>
			<hr>
		</table>
		
		<table id = "Q&As" align=center width=720px>
				<center><h1> Q&As </h1></center>
				Q0: License issue:<br>
				A0: The annotations of iMiGUE are copyright by us and published under the Creative Commons Attribution-NonCommercial 4.0 International License.<br>
				这个许可证的回答我也不太确定<br>
				<br>
				Q1: What do I need to do if I want to use the imigue dataset?<br>
				A1: Please submit a Google form at <a href='https://forms.gle/z8iTwRhdMsfRCNkm7'>this link</a>.
				We may reach you shortly.<br>
				还没有制作谷歌表单<br>
				需要和您确定一下表单上的问题<br>
				<br>

		</table>



		 <br><br>
		 <hr>

		 <table align=center width=720px>
			<center><h1>Paper</h1></center>
			   <tr>
				The original text of our paper can be seen <a href = './paper/imigue.pdf'>here</a>.<br>
				这里我是直接链接到了论文的。<br>
				<br>
				If you want to know more about the imigue dataset, the supplementary material can be seen <a href = './paper/supp.pdf'>here</a>.<br>
				这里也是<br>
				<br>
				

			 </tr>
		   </table>
		 
		 <br><br>
		 <hr>

		  <table align=center width=800px>
			<center><h1>Cite</h1></center>
		  <div class="disclaimerbox">
			<!-- <center><h2>How to interpret the results</h2></center> -->

		   <span>
				<!-- <center><span style="font-size:28px"><b>Cite</b></span></center> -->
				<pre style = "font-family:Courier; font-size:12px">
@inproceedings{linuxsinoiMiGUE,
title={iMiGUE: An Identity-free Video Dataset for Micro-Gesture Understanding and Emotion Analysis},
author={Xin Liu, Henglin Shi, Haoyu Chen, Zitong Yu, Xiaobai Li, Guoying Zhao},
booktitle={IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
year={2021}
}
				</pre>
		  </div>
  		  </table>

			<br><br>
			<hr>
  
		  	
  		  <table align=center width=720px>
  			  <tr>
  	              <td width=400px>
  					<left>
	  		  <center><h1>Acknowledgements</h1></center>

				The template of this webpage is borrowed from <a href='https://sdolivia.github.io/FineGym/'>FineGym</href><a>.
			</left>
		</td>
			 </tr>
		</table>

		<br><br>
		<hr>

		<table align=center width=720px>
			<tr>
				<td width=400px>
				  <left>
			<center><h1>Contact</h1></center>
			For further questions and suggestions, please contact Xin Liu (<a href='mailto:xliuoulu@gmail.com'>xliuoulu@gmail.com</a>).
			
			
		</left>
	</td>
		 </tr>
	</table>

		<br><br>

<script>
	
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-75863369-1', 'auto');
  ga('send', 'pageview');

</script>
              
</body>
</html>